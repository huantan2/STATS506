---
title: "RECS Case Study: Methods for GLMs"
author: "Statistics 506, Fall 2017"
date: ""
output: 
    html_document:
      theme: journal
      highlight: pygments
      css: styles.css
      toc: TRUE
      toc_depth: 4
      toc_float: TRUE
---

[Course Homepage](https://jbhender.github.io/Stats506/)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## S3 in Action - Methods for the GLM Class
 
In this example we will look at methods associated with the `glm`
class of objects representing models fits from [generalized linear models](https://en.wikipedia.org/wiki/Generalized_linear_model).

Just as the name implies, GLMs _generalized_ the linear model through
the use of a _link_ function relating the expected or mean outcome to a 
_linear predictor_. 

Generalized linear models
have the following form relating a dependent variable $Y$ to independent variables
$X$ and coefficients $\beta$:

$$
h(E[Y| X]) = X\beta.
$$

Here $h(\cdot)$ is called the _link function_ and we will often be interested in
its inverse $g(\cdot)$ so that an equivalent specification is:

$$
E[Y | X] = g(X\beta).
$$
The matrix product $X\beta$ in a generalized linear model is known as the _linear predictor_.

Classical linear regression has this form with the _identity link_ $h(x) = g(x) = x$,

$$
E[Y | X] = X\beta.
$$
Two popular GLMs are:

  + logistic regression for binary data with the _logit link_
$h(x) = log(x/(1-x))$ giving the model 

  $$
  \log \frac{ P(Y = 1 | X) }{P(Y = 0|X)} = X\beta,
  $$

  + Poisson regression for count data with the _log link_ $h(x) = \log(x)$
  
  $$
  \log E[Y | X] = X\beta.
  $$

### GLMs in R
Generalized linear models can be fit in $R$ using the `glm()` function. The first
argument is `formula` used for specifying the linear predictor in terms of one
or more columns from a data frame.  The other key argument is `family` which determines
the specific model to be fit.

### Case Study: Energy Star Compliance

In this first case study we will use logistic regression to explore predictors
of whether a home's primary fridge is Energy Star compliant.  For simplicity, we
will assume this is a simple random sample and ignore the survey weights. You can
find a version of this example in Stata [here](./RECS_ES.do).

First, we will load the [RECS data](./recs2009_public.RData) and clean up some variables of interest.

```{r data, warning=FALSE, message=FALSE}
## load packages
library(tidyverse) 

## read or load data
data_file = './recs2009_public.RData'
if(!file.exists(data_file)){
  recs = read_delim('./recs2009_public.csv', col_names=TRUE, delim=',')
  save(recs,file=data_file)
} else{
  foo = load(data_file)
  cat(sprintf('Loaded object(s) %s from %s.\n',foo,data_file))
}

## tidy data
# function to decode region
decode_region = function(rvec){
  sapply(rvec, function(r) switch(r, "NE", "MW", "S", "W"))
}

recs = recs %>% 
  mutate(es_fridge = ifelse(ESFRIG < 0, NA, ESFRIG),
                       totsqft = TOTSQFT / 100,
                       region = decode_region(REGIONC)
        ) %>% 
  filter(!is.na(es_fridge))
```

Now we are ready to fit a logistic regression.  Note that R will treat
"region" as a factor since it is of class `r typeof(recs$region)`.

```{r}
fit0 = glm(es_fridge ~ 0 + region + totsqft, data=recs,
           family=binomial(link='logit'))
summary(fit0)
class(fit0)
typeof(fit0)
```

Notice that the `glm` class _inherits_ from the `lm` class for linear models. 
Above we used the `summary` method to review the model fit `fit0`.  Here are some
other S3 methods we can make use of:

```{r}
print(fit0)
coef(fit0)
round(vcov(fit0),4)
broom::tidy(fit0)
```

Be careful about inheritance if you try to use the `plot` method as plots for
linear models may not be the most instructive for GLMs.

```{r}
methods(plot)[grep('lm', methods(plot))]
```

Another useful generic is `predict` for using the fitted model to predict 
expected values for new data. Below, we use predict to compute
"adjusted predictions at the mean" for the region and square footage variables.

#### Adjusted Predictions

##### Adjusted Predictions at the Mean(s) 

Here  we compute adjusted predictions (aka "predictive margins")
for regions at the mean for total square feet.  

```{r}
## Set up a new data frame
recs_regions_atmean = 
  tibble(region=unique(recs$region)) %>%
  mutate(totsqft=mean(recs$totsqft))

## Use predict to estimate
## probabilities for the new data
m0 = predict(fit0, recs_regions_atmean, type='response', se=TRUE)

## We can include these in the data frame and plot to compare
recs_regions_atmean %>%
  mutate(fit=m0$fit, se=m0$se.fit, lwr=fit - 2*se, upr=fit + 2*se) %>%
  mutate(region=factor(region,region[order(fit)])) %>% # order
  ggplot(aes(y=region, x=fit)) +
  geom_point() + 
  geom_errorbarh(aes(xmin=lwr, xmax=upr)) + 
  xlab('Predicted probability for average-sized house') +
  ggtitle('Estimated usage of Energy Star compliant refrigerators by region.')
```

What if we wanted to examine the effect of `totsqft` averaged over regions? 

```{r p_regions}
# Compute proportions of homes in each region
df_regions =
  recs %>% 
  group_by(region) %>%
  summarize(Count=n()) %>%
  spread(region,Count) %>%
  mutate(Total=MW+NE+S+W,
         MW=MW/Total, 
         NE=NE/Total,
         S =S/Total,
         W =W/Total
  ) %>%
  gather(region, prop, MW:W)

p_regions = df_regions$prop
names(p_regions) = df_regions$region
p_regions
```

```{r apm_totsqft}
# Compute linear predictors
at_totsqft = c(10, 20, 30)
lp_avg_region = sum(coef(fit0)[-5] * p_regions)
lp = lp_avg_region + coef(fit0)[5]*at_totsqft

# Use inverse link to compute response
pred = exp(lp)/{1 + exp(lp)}
ap_totsqft = tibble(totsqft = at_totsqft, adjusted_prediction = pred)
ap_totsqft
```

We could also do this using `predict`.

```{r}
## Using predict
new_data = recs %>% select(region, totsqft)

p10 = predict(fit0, new_data %>% mutate(totsqft=10), type='link')
p20 = predict(fit0, new_data %>% mutate(totsqft=20), type='link')
p30 = predict(fit0, new_data %>% mutate(totsqft=30), type='link')
pred = sapply(list(p10, p20, p30), function(x) exp(mean(x)) / {1 + exp(mean(x))})
ap_totsqft %>% mutate(adj_pred = pred)
```

In the above example, we computed predictions for each observation in the data set 
adjusted for fixed values of `totsqft` and averaged the _linear predictors_ 
**before**
transforming to the probability scale using the link function.  These
are examples of _adjusted predictions at the means_.

##### Average Adjusted Predictions

An alternative to adjusted predictions at the means are _average
adjusted predictions_ computed by averaging adjusted predictions for
each observation in the data set. In the example below, we average **after**
forming adjusted predictions on the probability scale, i.e the scale of the response.
In this case the results are rather similar.

```{r}
new_data = recs %>% select(region, totsqft)

p10 = predict(fit0, new_data %>% mutate(totsqft=10), type='response')
p20 = predict(fit0, new_data %>% mutate(totsqft=20), type='response')
p30 = predict(fit0, new_data %>% mutate(totsqft=30), type='response')
ap_totsqft %>% mutate(avg_response = sapply(list(p10, p20, p30), mean))
```

##### Factors, Interactions, and linked Covariates

Suppose we fit a model with an interaction between region and home size.

```{r}
fit1 = glm(es_fridge ~ 0 + region*totsqft, 
           data=recs, family=binomial(link='logit')
           )
summary(fit1)
```

When computing adjusted predictions at specific values of `totsqft` it would not
make sense to average over the interaction terms which also involve `totsqft`.
Instead, we should ensure that `totsqft` enters the model as expected for all 
terms involving it. Using `predict` will take care of this for us.

```{r}
p10 = predict(fit1, new_data %>% mutate(totsqft=10), type='response')
p20 = predict(fit1, new_data %>% mutate(totsqft=20), type='response')
p30 = predict(fit1, new_data %>% mutate(totsqft=30), type='response')
ap_totsqft = ap_totsqft %>% mutate(avg_response = sapply(list(p10, p20, p30), mean))
ap_totsqft
```

We could also do this directly.

```{r}
# model coefficients
beta_hat = matrix(coef(fit1), ncol=1)

# Data matrices for each level of totsqft
X10 = recs %>%
  transmute(
    MW = 1*{region=='MW'},
    NE = 1*{region=='NE'},
    S  = 1*{region=='S'},
    W  = 1*{region=='W'},
    tot = 10,
    tot_NE = tot*NE,
    tot_S  = tot*S,
    tot_W  = tot*W
  )
X10 = as.matrix(X10)
X20 = cbind(X10[,1:4], 2*X10[,5:8])
X30 = cbind(X10[,1:4], 3*X10[,5:8])

# inverse link
inv_logit = function(x) exp(x) / {1+exp(x)}

# average adjusted predictions
ap_totsqft %>% 
  mutate(
   by_hand = c( mean(inv_logit(X10 %*% beta_hat)), 
                mean(inv_logit(X20 %*% beta_hat)),
                mean(inv_logit(X30 %*% beta_hat))
              )
  )
```

##### The `prediction` package

The [prediction](https://github.com/leeper/prediction/) package provides
an S3 generic `prediction` and methods for computing
predictive margins from various classes representing fitted models. It is "type safe" in that it 
always returns an object of class `prediction` which 
is essentially a copy of the original data frame with the requested
fitted values plus a few additional attributes.  

Below we use `prediction::prediction` to compute adjusted predictions at the mean
for our `fit0` object.

```{r}
library(prediction)
lp_fit0 = prediction(fit0, at=list(totsqft=c(10, 20, 30)), type='link')
class(lp_fit0)
names(attributes(lp_fit0))
```

Because we requested predictions at three values of `totsqft` our data frame
is three time as large. 

```{r}
cat(' dim(lp_fit0): ', dim(lp_fit0), '\n', 'dim(recs): ', dim(recs),'\n',
    'nrow(lp_fit0)/nrow(recs): ', nrow(lp_fit0)/nrow(recs), '\n')
```

You should keep this in mind if working with large data sets as this could 
quickly eat up memory unnecessarily. This is also true of model objects returned
by `glm` itself.  

```{r}
print(object.size(recs), units='Mb')
print(object.size(lp_fit0), units='Mb')
object.size(lp_fit0) / object.size(recs)
print(object.size(fit0), units='Mb')
```

One way to minimize the impact of this is to fit models using data frames
limited to necessary variables.

```{r}
recs_glm = recs %>% select(es_fridge, region, totsqft)
fit0 = glm(es_fridge~0+region+totsqft, family=binomial(link='logit'), data=recs_glm)
fit1 = glm(es_fridge~0+region*totsqft, family=binomial(link='logit'), data=recs_glm)

print(object.size(recs_glm), units='Mb')
print(object.size(recs_glm), units='Mb')
print(object.size(fit0), units='Mb')
```

Returning to the theme of computing adjusted predictions, here are average
adjusted predictions using `type = 'response'` (the default).

```{r}
m_totsqft = prediction(fit0, at=list(totsqft=c(10, 20, 30)), type='response')
m_totsqft
```

__Question__ _Why doesn't `m_totsqft` print the entire data frame in the last
line above?_



##### Summary 

  + _Adjusted predictions at the mean_ are computed by fixing the values of
 some variables at representative values and setting others to the mean value.

  + _Average adjusted predictions_ are computed adjusted predictions for each
  observation in the data leaving other values unchanged and then averaging the
  resulting predictions.
 
  + In a linear model these are the same. 
 
  + In GLMs:
    + _adjusted predictions at the
 mean_ can be computed by _averaging adjusted linear predictors_ from each observation 
 in the data,
    + _average adjusted predictions_ instead average over the response.
 
#### Marginal or Partial Effects

Marginal effects (aka partial effects) summarize the impact of a model coefficient
using differences between adjusted predictions.  For factor variables this means
comparing each factor level to a reference level. For continuous variables we
may define marginal effects between reference levels of interest, 
often based on quantiles, or using a derivative. 


##### Marginal Effects at the Mean

As you might expect, _marginal effects at the mean_ (MEM) are differences between
_adjusted predctions at the mean_.  Below are some examples.

First, we examine simple differences of adjusted predictions at the mean
for different regions.
```{r mem_region}
# New data for prediction
new_data = 
  tibble(region  = unique(recs_glm$region),
         totsqft = mean(recs_glm$totsqft)
  )

# Predictions
new_data = 
  new_data %>%
  mutate(fitted = predict(fit0, new_data, type='response'))

# Compute differences
new_data %>% spread(region, fitted) %>%
  mutate(mem_NE = NE - MW,
         mem_S  = S  - MW,
         mem_W  = W  - MW
         ) %>% 
  knitr::kable(digits=2)
```

Next, we compute marginal effects at the mean for `totsqft`.
```{r mem_totsqft}
# MEM for totsqft quantiles
q_tot = quantile(recs_glm$totsqft, c(.25, .75))

# Adjusted Predictions at "mean" region
lp_fit0 = c(sum(coef(fit0)*c(p_regions, q_tot[1])),
            sum(coef(fit0)*c(p_regions, q_tot[2]))
            )
apm = exp(lp_fit0) / {1 + exp(lp_fit0)}    
apm

# Marginal Effect
diff(apm)
```

From the above, for an "average" region a house at the upper quartile
(~`r round(q_tot[2])*1e2` sq ft) is `r round(diff(apm)*100)`% more likely to have
an Energy Star compliant refrigerator than a house at the lower quartile 
(~`r round(q_tot[1])*1e2` sq ft).

##### Average Marginal Effects

Similarly, _average marignal effects_ (AME) are differences between
average adjusted predictions. 

Below we first compute predictions for each region at the chosen
levels of `totsqft`

```{r ame_totsqft}
# AME for totsqft qu0antiles
q_tot = quantile(recs_glm$totsqft, c(.25, .75))

# New data for prediction
new_data = 
  tibble(totsqft = rep(q_tot, each=4),
         region = rep(names(p_regions), 2),
         w_regions = rep(p_regions, 2)
  )

            

new_data = new_data %>% mutate(fitted = predict(fit0, new_data, type='response'))

new_data
```

Now, we can compute a weighted average of the marginal effects.

```{r}
aap = new_data %>% group_by(totsqft) %>% summarize(ame = sum(w_regions*fitted))
with(aap, ame[2] - ame[1])
```

This could also be done using `predict`.

```{r}
aap_upr = 
  mean(predict(fit0, recs_glm %>% mutate(totsqft = q_tot[2]), type='response'))
aap_lwr =
  mean(predict(fit0, recs_glm %>% mutate(totsqft = q_tot[1]), type='response'))
c('Lower Q'=aap_lwr, 'Upper Q'=aap_upr, 'AME' = aap_upr - aap_lwr)
```


##### The `margins` package

The author of the `prediction` package also has a [margins package](https://github.com/leeper/margins/)
meant to mimic the behavior of Stata's `margins` command. As you might expect, it
is built on the `prediction` package meaning that functions in `margins` call functions in
`prediction` for computing adjusted predictions.  

```{r, warning=FALSE}
library(margins)
mem0 = margins(fit0)
mem0
plot(mem0)
```

What happens when we call margins? Below is a _call graph_ for
functions in the `margins` package.
```{r}
mvbutils::foodweb(where=asNamespace("margins"))
```

##### Computing marginal effects

We can call margins directly using the "change" parameter to specify
we want continuous variables summarized using differences between adjusted
predictions at the upper and lower quartiles.

```{r}
margins(fit0, change='iqr')
```


For factor variables, "dydx" is the first difference between the predicted
response at a particular level of the factor and the predicted response at the
baseline level. For numeric variables, the default behavior is to use a numeric
derivative at the observed value for each observation.  Below we investigate
this for our earlier call creating the margins data frame `mem0`.

```{r}
dydx_W = 
  predict(fit0, recs_glm %>% mutate(region='W'), type='response') - 
  predict(fit0, recs_glm %>% mutate(region='MW'), type='response')
head(cbind(dydx_W, dydx_regionW = mem0$dydx_regionW))
```

The overall marginal effect is the average adjusted difference.

```{r}
mean(dydx_W)
mem0
```

In the next code block, we look at the computation of the 'numeric' 
derivatives for continuous variables like `totsqft`.

```{r}
# Step size
setstep = function(x){
  max(abs(x), 1, na.rm=TRUE)*sqrt(1e-7)
}
recs_glm = recs_glm %>% mutate(h = sapply(totsqft, setstep))

# Numeric differentiation
dydx_totsqft = 
  {
    predict(fit0, 
            recs_glm %>% mutate(totsqft = totsqft + .5*h),
            type='response'
    ) - 
    predict(fit0,
          recs_glm %>% mutate(totsqft = totsqft - .5*h),
          type='response'
    )
  } / {recs_glm$h}

dydx_compare = 
  cbind("mem0"=mem0$dydx_totsqft, "dydx"=dydx(recs_glm, fit0, "totsqft"),
           "hand"=dydx_totsqft)
head(dydx_compare)
```

The average marginal effect of `totsqft` is the average of these values.

```{r}
apply(dydx_compare, 2, mean)
```

```{r}
mem0
```

We can also use "at" to select representative values at which
we wish to see marginal effects.  Using our interaction model,
we can summarize the marginal effect of region at different levels
of `totsqft`.

```{r}
mem1 = margins(fit1, at=list(totsqft=q_tot))
mem1
```

Here are some plots to help us visualize the interactions.

```{r}
mem1a = margins(fit1)
mem1a %>%
  ggplot(aes(x=totsqft, y=fitted, group=region, color=region)) +
  geom_line()
```

```{r}
mem1a %>%
  ggplot(aes(x=totsqft, y=fitted, group=region, color=region)) +
  geom_line() + 
  geom_point(aes(y=es_fridge)) +
  facet_wrap(~region)
```

##### Summary
 
  + _Marginal effects at the mean_ represent differences
  in adjusted predictions at the mean.

  + _Average marginal effects_ represent differences in average
  adjusted predictions. This is equivalent to the mean marginal effect computed from adjusted predictions for each observation in the data since averaging and
  difference are linear operations.
 
  + For continuous values we can computed marginal effects by difference
  adjusted predictions at representative values or use derivatives in place of differences. 



